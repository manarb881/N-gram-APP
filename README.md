# N-gram Language Model

A statistical language model that predicts the next word in a sequence using N-gram probabilities and smoothing techniques.

---

## **What It Does**

- Builds **N-gram models** (unigram, bigram, trigram) from raw text  
- Implements **Laplace smoothing** and **Add-k smoothing** to handle unseen word combinations  
- Evaluates model performance using:
  - **Perplexity**
  - **Accuracy**
- Predicts the **most likely next word** given a context window  
- Compares different:
  - preprocessing strategies  
  - model configurations (n, smoothing type, vocabulary size)

---
